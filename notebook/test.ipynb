{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2354efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import qa\n",
    "importlib.reload(qa)\n",
    "import qa\n",
    "\n",
    "import plot\n",
    "from plot import plot_from_file\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import random\n",
    "import ast\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import ttest_rel\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fd041d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../data/MMLU-Pro/sample_results/grp_count.pkl', 'rb') as f:\n",
    "    temp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f7a07fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing grp_count samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 1/15000 [00:00<3:20:35,  1.25it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m         input_row.append(eval_feat)\n\u001b[32m     31\u001b[39m     input_feat_list.append(input_row)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m results, accuracy = \u001b[43mqa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mqa_eval_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres_org\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feat_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m results = previous_results + results\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m../data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbenchmark\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/sample_results/grp_count.pkl\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ssd/yc936/crowd_psych/notebook/../src/qa.py:685\u001b[39m, in \u001b[36mqa_eval_matrix\u001b[39m\u001b[34m(qa_input, input_feat_list, num_workers)\u001b[39m\n\u001b[32m    682\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m samples...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    684\u001b[39m \u001b[38;5;66;03m# flatten_results = batch_multiprocess(input_list, func, num_workers, batch_size = 1000)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m flatten_results = \u001b[43mmultithreading\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[38;5;66;03m# deflatten the results back to the original shape\u001b[39;00m\n\u001b[32m    688\u001b[39m results = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ssd/yc936/crowd_psych/notebook/../src/qa.py:66\u001b[39m, in \u001b[36mmultithreading\u001b[39m\u001b[34m(input_list, func, num_workers)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmultithreading\u001b[39m(input_list, func, num_workers):\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers=num_workers) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m         results = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mProcessing\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/herd_behavior/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/herd_behavior/lib/python3.11/concurrent/futures/_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[32m    617\u001b[39m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    621\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs.pop(), end_time - time.monotonic())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/herd_behavior/lib/python3.11/concurrent/futures/_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    319\u001b[39m         fut.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/herd_behavior/lib/python3.11/concurrent/futures/_base.py:451\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_condition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/herd_behavior/lib/python3.11/threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "benchmarks = [\"MMLU-Pro\", \"GPQA-Diamond\", \"ARC\", \"OpinionQA\", \"GlobalOpinionQA\", \"SIQA\"]\n",
    "factual = [\"MMLU-Pro\", \"GPQA-Diamond\", \"ARC\"]\n",
    "opinion = [\"OpinionQA\", \"GlobalOpinionQA\", \"SIQA\"]\n",
    "\n",
    "for benchmark in benchmarks:\n",
    "\n",
    "    with open(f'../data/{benchmark}/sample_results/org.pkl', 'rb') as f:\n",
    "        res_org = pickle.load(f)\n",
    "\n",
    "    with open(f'../data/{benchmark}/sample_results/grp_count.pkl', 'rb') as f:\n",
    "        previous_results = pickle.load(f)\n",
    "\n",
    "    input_feat_list = []\n",
    "    for disagree_size in range(1, 11): # row\n",
    "        input_row = []\n",
    "        for agree_size in range(1, 11): # column\n",
    "\n",
    "            if agree_size <= 5 and disagree_size <= 5:\n",
    "                continue\n",
    "\n",
    "            \n",
    "            eval_feat = {\n",
    "                'type': 'grp_count',\n",
    "                'agree_size': agree_size,\n",
    "                'disagree_size': disagree_size,\n",
    "                'disagree_type': '2nd',\n",
    "                'q_type': 'factual' if benchmark in factual else 'opinion',\n",
    "                'order': 'random'\n",
    "            }\n",
    "            input_row.append(eval_feat)\n",
    "        input_feat_list.append(input_row)\n",
    "\n",
    "    results, accuracy = qa.qa_eval_matrix(res_org, input_feat_list)\n",
    "\n",
    "    results = previous_results + results\n",
    "\n",
    "    with open(f'../data/{benchmark}/sample_results/grp_count.pkl', 'wb') as f:\n",
    "        pickle.dump(results, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "herd_behavior",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
