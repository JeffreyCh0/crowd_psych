import json

import sys
sys.path.append('../src')
from agent import Agent, top_norm_prob
import numpy as np
import multiprocess as mp
from tqdm import tqdm
import random
import pickle
from copy import deepcopy

if sys.platform == "darwin":  # macOS check
    mp.set_start_method("spawn", force=True)

def QA(question:str, choices:list):
    qa_agent = Agent()
    str_choices = zip(range(len(choices)), choices)
    alpha = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
    str_choices = "\n".join([f"{alpha[idx]}. {choice}" for idx, choice in str_choices])
    qa_agent.load_message([{"role": "user", "content": f"# Question: \n{question} # Choices: \n{str_choices}"}])
    response_format={
        "type": "json_schema",
        "json_schema": {
        "name": "multiple_choice_response",
        "strict": True,
        "schema": {
            "type": "object",
            "properties": {
            "response": {
                "type": "string",
                "description": "The letter corresponding to the answer.",
                "enum": [alpha[idx] for idx in range(len(choices))]
            }
            },
            "required": [
                "response"
            ],
            "additionalProperties": False
        }
        }
    }
    response_json, response_logprobs = qa_agent.get_response(response_format = response_format, logprobs = True, temperature = 0)
    response = json.loads(response_json)["response"]
    top_prob = top_norm_prob(response_logprobs, response)
    top_prob_list = [(x.token, round(np.exp(x.logprob), 4)) for x in list(response_logprobs[3].top_logprobs)][:len(choices)]
    return response, top_prob, top_prob_list

def process_org(input_ele):
    # Process a single MMLU sample.
    # takes mmlu data as input
    # output is _org data
    ele = deepcopy(input_ele)
    question = ele['question']
    choices = ele['options']
    pred, prob, topk = QA(question, choices)
    ele['r'] = pred
    ele['p_r'] = prob
    ele['topk'] = topk
    return ele  # Return updated sample

def process_one(ele, disagree_type):
    # Process a single MMLU sample.
    # takes _org data as input, which should be generated by process_org()
    # output is _one_rnd data
    if disagree_type == 'rnd:':
        prev_topk = ele['topk']
        prev_r = ele['r']
        r_j_pool = [x for x in prev_topk if x[0] != prev_r]
        r_j_tuple = random.Random(0).choice(r_j_pool)
        r_j = r_j_tuple[0]
        p_r_j = r_j_tuple[1]
    elif disagree_type == '1st':
        r_j = ele['r']
        p_r_j = ele['p_r']
    elif disagree_type == '2nd':
        prev_topk = ele['topk']
        r_j = prev_topk[1][0]
        p_r_j = prev_topk[1][1]
    elif disagree_type == 'lst':
        prev_topk = ele['topk']
        r_j = prev_topk[-1][0]
        p_r_j = prev_topk[-1][1]


    question = ele['question'] + f"# Other's Response:\n Another agent thinks the answer is {r_j}."
    choices = ele['options']
    pred, prob, topk = QA(question, choices)
    ele['r_j'] = r_j
    ele['p_r_j'] = p_r_j
    ele['r'] = pred
    ele['p_r'] = prob
    ele['topk'] = topk
    return ele  # Return updated sample

def process_grp_count(args):
    # Process a single MMLU sample.
    # takes _org data as input, which should be generated by process_org()
    # output is _grp data

    input_ele, agree_size, disagree_size, disagree_type = args

    ele = deepcopy(input_ele)

    prev_topk = ele['topk']
    R_p = ele['r']
    p_R_p = ele['p_r']
    if disagree_type == "2nd":
        R_n = prev_topk[1][0]
        p_R_n = prev_topk[1][1]

    question = ele['question'] 
    if agree_size + disagree_size > 0:
        question += f"# Other's Response:\n"

    if agree_size > 0:
        question += f"{agree_size} agents think the answer is {R_p}.\n"

    if disagree_size > 0:
        question += f"{disagree_size} agents think the answer is {R_n}.\n"

    
    choices = ele['options']
    pred, prob, topk = QA(question, choices)
    ele['R_p'] = R_p # positive response from the group
    ele['R_n'] = R_n # negative response from the group
    ele['p_R_p'] = p_R_p
    ele['p_R_n'] = p_R_n
    ele['r'] = pred
    ele['p_r'] = prob
    ele['topk'] = topk
    ele['agree_size'] = agree_size
    ele['disagree_size'] = disagree_size
    ele['disagree_type'] = disagree_type
    return ele  # Return updated sample

def process_grp_ratio(args):
    # Process a single MMLU sample.
    # takes _org data as input, which should be generated by process_org()
    # output is _grp data

    input_ele, group_size, disagree_ratio, disagree_type = args

    ele = deepcopy(input_ele)

    prev_topk = ele['topk']
    R_p = ele['r']
    p_R_p = ele['p_r']
    if disagree_type == "2nd":
        R_n = prev_topk[1][0]
        p_R_n = prev_topk[1][1]

    str_disagree_ratio = str(round(disagree_ratio*100))
    str_agree_ratio = str(round((1-disagree_ratio)*100))

    question = ele['question'] 
    question += f"# Other's Response:\n"
    question += f"Among {group_size} agents,\n"
    question += f"{str_disagree_ratio}% think the answer is {R_n}.\n"
    question += f"{str_agree_ratio}% think the answer is {R_p}.\n"

    
    choices = ele['options']
    pred, prob, topk = QA(question, choices)
    ele['R_p'] = R_p # positive response from the group
    ele['R_n'] = R_n # negative response from the group
    ele['p_R_p'] = p_R_p
    ele['p_R_n'] = p_R_n
    ele['r'] = pred
    ele['p_r'] = prob
    ele['topk'] = topk
    ele['group_size'] = group_size
    ele['disagree_ratio'] = disagree_ratio
    ele['disagree_type'] = disagree_type
    return ele  # Return updated sample

def mmlu_eval_matrix(mmlu_input, input_feat_list, num_workers=mp.cpu_count()):
    """Evaluate MMLU samples using multiprocess for parallel execution with tqdm."""
    input_list = []
    nrows = len(input_feat_list)
    ncols = len(input_feat_list[0])
    n_ele = len(mmlu_input)
    for row in input_feat_list:
        for eval_feat in row:
            eval_type = eval_feat['type']

            if eval_type == 'grp_count':
                func = process_grp_count
                agree_size = eval_feat['agree_size']
                disagree_size = eval_feat['disagree_size']
                disagree_type = eval_feat['disagree_type']
                input_list.extend([(sample, agree_size, disagree_size, disagree_type) for sample in mmlu_input])
            elif eval_type == 'grp_ratio':
                func = process_grp_ratio
                group_size = eval_feat['group_size']
                disagree_ratio = eval_feat['disagree_ratio']
                disagree_type = eval_feat['disagree_type']
                input_list.extend([(sample, group_size, disagree_ratio, disagree_type) for sample in mmlu_input])

    print(f"Processing {eval_type} samples...")
    with mp.Pool(num_workers) as pool:
        flatten_results = list(tqdm(pool.imap(func, input_list), total=len(input_list), desc="Processing MMLU"))

    # deflatten the results back to the original shape
    results = []
    for i in range(nrows):
        row_results = []
        for j in range(ncols):
            row_results.append(flatten_results[(i*ncols*n_ele+j*n_ele):(i*ncols*n_ele+(j+1)*n_ele)])
        results.append(row_results)

    accuracy = []
    for row in results:
        row_acc = []
        for eles in row:
            row_acc.append(sum([ele['r'] == ele['answer'] for ele in eles])/len(eles))
        accuracy.append(row_acc)
    accuracy = np.array(accuracy)

    # with open(f"../data/group_da/mmlu_{disagree_type}.pkl", "wb") as f:
    #     pickle.dump(results, f)
    return results, accuracy  # Return processed samples

def mmlu_eval_org(mmlu_input, num_workers = mp.cpu_count()):
    with mp.Pool(num_workers) as pool:
        results = list(tqdm(pool.imap(process_org, mmlu_input), total=len(mmlu_input), desc="Processing MMLU"))
    return results
    

